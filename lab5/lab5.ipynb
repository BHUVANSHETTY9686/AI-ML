{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d2b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: \n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted Output: \n",
      " [[0.89506319]\n",
      " [0.88166845]\n",
      " [0.89297535]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array(([2,9],[1,5],[3,6]), dtype=float)\n",
    "Y=np.array(([92],[86],[89]),dtype=float)\n",
    "\n",
    "#dividing x by max in x\n",
    "Z=np.amax(X,axis=0)\n",
    "X=X/np.amax(X,axis=0)\n",
    "\n",
    "#dividing y by 100\n",
    "Y=Y/100\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def derivatives_sigmoid(X):\n",
    "    return X*(1-X)\n",
    "\n",
    "epoch=5000\n",
    "lr=0.1\n",
    "inputlayer_neurons=2\n",
    "hiddenlayer_neurons=3\n",
    "output_neurons=1\n",
    "\n",
    "\"\"\"np.random.uniform creates numpy array filled with values drawn from uniform distribution, uniform distribution draws number from range \n",
    "with constant probability\"\"\"\n",
    "\n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "bout=np.random.uniform(size=(1,output_neurons))\n",
    "\n",
    "#initialiaze weigtht and bias with random values \n",
    "#1-om next iteration iteration we use updateted weight and bias\n",
    "#2-ke matrix dot product of input and weight assigned to edge b/w input and hidden layer then add bias to hidden layer neuron respectively---this is called linear tranformation\n",
    "\n",
    "for i in range(epoch):\n",
    "    hinpl=np.dot(X,wh)\n",
    "    hinp=hinpl+bh\n",
    "    hlayer_act=sigmoid(hinp) #3- perform the non linear tranformation using activation funtion sigmoid formula:-sigmoid=1/(1+exp(-x)\n",
    "    outinpl=np.dot(hlayer_act,wout)\n",
    "    outinp=outinpl+bout\n",
    "    output=sigmoid(outinp)\n",
    "    E0=Y-output\n",
    "    \n",
    "    #4- perform linear tranformation on hidden layer activation apply activation funtion to predict output\n",
    "    #5- compare actual and predicted output compute gradient(error)\n",
    "    #6- compute slope by gradient of hidden and output layer neuron(to comput the slope we calculate diraivatives of non linear activation x for each neuron ....graident of sigmoid =x*(1-x)\n",
    "    \n",
    "    outgrad=derivatives_sigmoid(output)\n",
    "    \n",
    "    #7- compute change factor(delta) at output layer dependent on the gradeint of error multiplied by slope of output layer activation\n",
    "    d_output= E0*outgrad\n",
    "    #8- error back propagate into network which means we have to  send the error information to hidden layer for this we take dot product of output layer delta with weight parameters of edges b/w hidden and output layer\n",
    "    EH=d_output.dot(wout.T)\n",
    "    \n",
    "    #9-- compute change factor delta at hidden layer multiply the error at hidden layer with slope of hidden layer activation4\n",
    "    hiddengrad=derivatives_sigmoid(hlayer_act)\n",
    "    d_hiddenlayer=EH*hiddengrad\n",
    "    \n",
    "    #10- update weight at output and hidden layer weight in the network can be updateded from error calcuated for training example.\n",
    "    \n",
    "    wout+=hlayer_act.T.dot(d_output)*lr\n",
    "    wh+=X.T.dot(d_hiddenlayer)*lr\n",
    "\n",
    "print(\"Input: \\n\" + str(X)) \n",
    "print(\"Actual Output: \\n\" + str(Y)) \n",
    "print(\"Predicted Output: \\n\" ,output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd603c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
